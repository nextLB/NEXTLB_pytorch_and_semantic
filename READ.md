    
# 基于pytorch与segmentation-models-pytorch的语义分割项目

## 环境的配置
    详见ENVIRONMENT.md文件中的内容

## 项目说明
    本项目非常适合于初步接触深度学习尤其是神经网络中语义分割模型技术的学者来学习的
    请前来学习的学者一定要仔细的阅读我的每个程序文件的代码，答案尽在代码之中


### CNN_pytorch
    CNN() 作为计算机视觉领域非常经典的模块，我们首先当然要看一下它了
    根据我的整个项目的构造，请前往我的CNN文件夹中查看详细的实现代码


### DINOV2
    DINOv2(Discrete Instance-wise Normalization for Vision Transformers Version 2)
    是由Meta AI研究团队推出的一种基于自监督学习的先进视觉模型架构。它能够从不带任何标签的图像中学习强大且通用的
    视觉特征，这些特征可以直接应用于多种下游任务（如图像分类、语义分割、深度估计等），而通常无需进行任务特定的微
    调(即零样本或线性评估能力)。

    下面是对其架构和工作原理的详细解释。为了帮你快速了解DINOv2，我用一个表格来概括它的主要特点：
    --------------------------------------------------------------------------------
    方面	描述
    核心架构	基于 Vision Transformer (ViT)，作为模型的主干网络。
    训练核心	采用自我蒸馏（Self-Distillation）和师生架构（Student-Teacher）。
    训练目标	结合图像级（Image-level）和块级（Patch-level）的自监督目标。
    关键技术	使用 FlashAttention、嵌套张量、高效随机深度等技术提升训练效率和稳定性。
    数据处理	利用大规模、高质量数据集（如LVD-142M），并经过严格去重和过滤。
    模型缩放	提供多种规模的模型（ViT-S, ViT-B, ViT-L, ViT-G），并支持知识蒸馏到更小模型。
    主要应用	图像分类、语义分割、实例检索、深度估计、视频理解等。
    突出优势	强大的零样本性能、对图像本质特征的理解、无需大量标注数据、可迁移性强。
    --------------------------------------------------------------------------------
    
    根据我的整个项目的构造，请前往我的DINO2文件夹中查看详细的实现代码
